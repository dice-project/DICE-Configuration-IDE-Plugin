<?xml version="1.0"?>
<params>
   <intparam>
      <name>topology.min.replication.count</name>
      <node>storm</node>
      <default>1</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.min.replication.wait.time.sec</name>
      <node>storm</node>
      <default>60</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.worker.receiver.thread.count</name>
      <node>storm</node>
      <default>1</default>
      <lowerbound>0</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <boolparam>
      <name>topology.backpressure.enable</name>
      <node>storm</node>
      <default>false</default>
   </boolparam>
   <boolparam>
      <name>topology.enable.message.timeouts</name>
      <node>storm</node>
      <default>true</default>
   </boolparam>
   <intparam>
      <name>topology.workers</name>
      <node>storm</node>
      <default>1</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.message.timeout.secs</name>
      <node>storm</node>
      <default>30</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.shellbolt.max.pending</name>
      <node>storm</node>
      <default>100</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.executor.receive.buffer.size</name>
      <node>storm</node>
      <default>1024</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.executor.send.buffer.size</name>
      <node>storm</node>
      <default>1024</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.worker.shared.thread.pool.size</name>
      <node>storm</node>
      <default>4</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.sleep.spout.wait.strategy.time.ms</name>
      <node>storm</node>
      <default>1</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.error.throttle.interval.secs</name>
      <node>storm</node>
      <default>10</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.trident.batch.emit.interval.millis</name>
      <node>storm</node>
      <default>500</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.disruptor.wait.timeout.millis</name>
      <node>storm</node>
      <default>1000</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.disruptor.batch.size</name>
      <node>storm</node>
      <default>100</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.disruptor.batch.timeout.millis</name>
      <node>storm</node>
      <default>1</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <boolparam>
      <name>topology.disable.loadaware.messaging</name>
      <node>storm</node>
      <default>false</default>
   </boolparam>
   <intparam>
      <name>topology.state.checkpoint.interval.ms</name>
      <node>storm</node>
      <default>1000</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.max.task.parallelism</name>
      <node>storm</node>
      <default>-1</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.max.spout.pending</name>
      <node>storm</node>
      <default>-1</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.acker.executors</name>
      <node>storm</node>
      <default>-1</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>topology.tick.tuple.freq.secs</name>
      <node>storm</node>
      <default>-1</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
   </intparam>
   <intparam>
      <name>mapreduce.task.io.sort.factor</name>
      <node>hadoop</node>
      <default>10</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
      <description>The number of streams to merge at once while sorting files. This determines the number of open file handles.</description>
   </intparam>
   <intparam>
      <name>mapreduce.task.io.sort.mb</name>
      <node>hadoop</node>
      <default>100</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
      <description>The total amount of buffer memory to use while sorting files, in megabytes. By default, gives each merge stream 1MB, which should minimize seeks.</description>
   </intparam>
   <intparam>
      <name>mapreduce.map.sort.spill.percent</name>
      <node>hadoop</node>
      <default>0.80</default>
      <lowerbound>0</lowerbound>
      <upperbound>1</upperbound>
      <description>The soft limit in the serialization buffer. Once reached, a thread will begin to spill the contents to disk in the background. Note that collection will not block if this threshold is exceeded while a spill is already in progress, so spills may be larger than this threshold when it is set to less than .5</description>
   </intparam>
   <intparam>
      <name>mapreduce.job.max.split.locations</name>
      <node>hadoop</node>
      <default>10</default>
      <lowerbound>1</lowerbound>
      <upperbound>2147483647</upperbound>
      <description>The max number of block locations to store for each split for locality calculation.</description>
   </intparam>
   <intparam>
      <name>mapreduce.reduce.shuffle.merge.percent</name>
      <node>hadoop</node>
      <default>0.66</default>
      <lowerbound>0</lowerbound>
      <upperbound>1</upperbound>
      <description>The usage threshold at which an in-memory merge will be initiated, expressed as a percentage of the total memory allocated to storing in-memory map outputs, as defined by mapreduce.reduce.shuffle.input.buffer.percent.</description>
   </intparam>
   <intparam>
      <name>mapreduce.reduce.shuffle.input.buffer.percent</name>
      <node>hadoop</node>
      <default>0.7</default>
      <lowerbound>0</lowerbound>
      <upperbound>1</upperbound>
      <description>The percentage of memory to be allocated from the maximum heap size to storing map outputs during the shuffle.</description>
   </intparam>
   <intparam>
      <name>mapreduce.reduce.input.buffer.percent</name>
      <node>hadoop</node>
      <default>0</default>
      <lowerbound>0</lowerbound>
      <upperbound>1</upperbound>
      <description>The percentage of memory- relative to the maximum heap size- to retain map outputs during the reduce. When the shuffle is concluded, any remaining map outputs in memory must consume less than this threshold before the reduce can begin.</description>
   </intparam>
   <intparam>
      <name>mapreduce.shuffle.max.threads</name>
      <node>hadoop</node>
      <default>0</default>
      <lowerbound>0</lowerbound>
      <upperbound>2147483647</upperbound>
      <description>Max allowed threads for serving shuffle connections. Set to zero to indicate the default of 2 times the number of available processors (as reported by Runtime.availableProcessors()). Netty is used to serve requests, so a thread is not needed for each connection.</description>
   </intparam>
   <boolparam>
      <name>mapreduce.map.speculative</name>
      <node>hadoop</node>
      <default>true</default>
      <description>If true, then multiple instances of some map tasks may be executed in parallel.</description>
   </boolparam>
   <boolparam>
      <name>mapreduce.reduce.speculative</name>
      <node>hadoop</node>
      <default>true</default>
      <description>If true, then multiple instances of some reduce tasks may be executed in parallel.</description>
   </boolparam>
   <intparam>
      <name>mapreduce.job.speculative.speculative-cap-running-tasks</name>
      <node>hadoop</node>
      <default>0.1</default>
      <lowerbound>0</lowerbound>
      <upperbound>1</upperbound>
      <description>The max percent (0-1) of running tasks that can be speculatively re-executed at any time.</description>
   </intparam>
   <intparam>
      <name>mapreduce.job.speculative.speculative-cap-total-tasks</name>
      <node>hadoop</node>
      <default>0.01</default>
      <lowerbound>0</lowerbound>
      <upperbound>1</upperbound>
      <description>The max percent (0-1) of all tasks that can be speculatively re-executed at any time.</description>
   </intparam>
   <boolparam>
      <name>mapreduce.job.ubertask.enable</name>
      <node>hadoop</node>
      <default>false</default>
      <description>Whether to enable the small-jobs "ubertask" optimization, which runs "sufficiently small" jobs sequentially within a single JVM. "Small" is defined by the following maxmaps, maxreduces, and maxbytes settings. Note that configurations for application masters also affect the "Small" definition - yarn.app.mapreduce.am.resource.mb must be larger than both mapreduce.map.memory.mb and mapreduce.reduce.memory.mb, and yarn.app.mapreduce.am.resource.cpu-vcores must be larger than both mapreduce.map.cpu.vcores and mapreduce.reduce.cpu.vcores to enable ubertask. Users may override this value.</description>
   </boolparam>
   <catparam>
      <name>map.sort.class</name>
      <node>hadoop</node>
      <default>org.apache.hadoop.util.QuickSort</default>
      <option>org.apache.hadoop.util.QuickSort</option>
      <option>org.apache.hadoop.util.HeapSort</option>
      <description>The default sort class for sorting keys.</description>
   </catparam>
   <intparam>
      <name>mapreduce.job.reduce.slowstart.completedmaps</name>
      <node>hadoop</node>
      <default>0.05</default>
      <lowerbound>0</lowerbound>
      <upperbound>1</upperbound>
      <description>Fraction of the number of maps in the job which should be complete before reduces are scheduled for the job.</description>
   </intparam>
</params>